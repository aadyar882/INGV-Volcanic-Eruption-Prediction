{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-09-29T06:01:34.647699Z","iopub.execute_input":"2022-09-29T06:01:34.648144Z","iopub.status.idle":"2022-09-29T06:01:34.844311Z","shell.execute_reply.started":"2022-09-29T06:01:34.648109Z","shell.execute_reply":"2022-09-29T06:01:34.843125Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/predict-volcanic-eruptions-ingv-oe/train.csv\")\nsample_submission = pd.read_csv(\"../input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-29T06:06:07.135428Z","iopub.execute_input":"2022-09-29T06:06:07.136753Z","iopub.status.idle":"2022-09-29T06:06:07.148343Z","shell.execute_reply.started":"2022-09-29T06:06:07.136705Z","shell.execute_reply":"2022-09-29T06:06:07.147596Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"file_dir = '../input/predict-volcanic-eruptions-ingv-oe/test'\n!ls $file_dir | wc -l","metadata":{"execution":{"iopub.status.busy":"2022-10-08T16:07:07.570705Z","iopub.execute_input":"2022-10-08T16:07:07.571968Z","iopub.status.idle":"2022-10-08T16:07:08.620550Z","shell.execute_reply.started":"2022-10-08T16:07:07.571909Z","shell.execute_reply":"2022-10-08T16:07:08.619155Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"4520\n","output_type":"stream"}]},{"cell_type":"code","source":"import glob\nimport os\nimport pandas as pd\nfiles = glob.glob(os.path.join(file_dir, \"*.csv\"))\nd1 = pd.read_csv(files[0])\nd1.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-08T16:10:02.221420Z","iopub.execute_input":"2022-10-08T16:10:02.221876Z","iopub.status.idle":"2022-10-08T16:10:02.406244Z","shell.execute_reply.started":"2022-10-08T16:10:02.221839Z","shell.execute_reply":"2022-10-08T16:10:02.405227Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  \\\n0    -511.0       NaN    -131.0    -457.0      47.0     -35.0     185.0   \n1    -556.0       NaN    -105.0    -534.0      -7.0     -84.0     190.0   \n2    -615.0       NaN     -97.0    -473.0     -50.0       8.0     219.0   \n3    -682.0       NaN     -75.0    -388.0     -58.0      28.0     255.0   \n4    -763.0       NaN     -18.0    -358.0     -53.0    -104.0     271.0   \n\n   sensor_8  sensor_9  sensor_10  \n0     367.0     858.0     -492.0  \n1     195.0     881.0     -368.0  \n2     327.0     937.0     -260.0  \n3    -249.0     995.0     -187.0  \n4    -162.0    1032.0     -160.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor_1</th>\n      <th>sensor_2</th>\n      <th>sensor_3</th>\n      <th>sensor_4</th>\n      <th>sensor_5</th>\n      <th>sensor_6</th>\n      <th>sensor_7</th>\n      <th>sensor_8</th>\n      <th>sensor_9</th>\n      <th>sensor_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-511.0</td>\n      <td>NaN</td>\n      <td>-131.0</td>\n      <td>-457.0</td>\n      <td>47.0</td>\n      <td>-35.0</td>\n      <td>185.0</td>\n      <td>367.0</td>\n      <td>858.0</td>\n      <td>-492.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-556.0</td>\n      <td>NaN</td>\n      <td>-105.0</td>\n      <td>-534.0</td>\n      <td>-7.0</td>\n      <td>-84.0</td>\n      <td>190.0</td>\n      <td>195.0</td>\n      <td>881.0</td>\n      <td>-368.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-615.0</td>\n      <td>NaN</td>\n      <td>-97.0</td>\n      <td>-473.0</td>\n      <td>-50.0</td>\n      <td>8.0</td>\n      <td>219.0</td>\n      <td>327.0</td>\n      <td>937.0</td>\n      <td>-260.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-682.0</td>\n      <td>NaN</td>\n      <td>-75.0</td>\n      <td>-388.0</td>\n      <td>-58.0</td>\n      <td>28.0</td>\n      <td>255.0</td>\n      <td>-249.0</td>\n      <td>995.0</td>\n      <td>-187.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-763.0</td>\n      <td>NaN</td>\n      <td>-18.0</td>\n      <td>-358.0</td>\n      <td>-53.0</td>\n      <td>-104.0</td>\n      <td>271.0</td>\n      <td>-162.0</td>\n      <td>1032.0</td>\n      <td>-160.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_features(signal, ts, sensor_id):\n    X = pd.DataFrame()\n    f = np.fft.fft(signal)\n    f_real = np.real(f)\n    X.loc[ts, f'{sensor_id}_sum']       = signal.sum()\n    X.loc[ts, f'{sensor_id}_mean']      = signal.mean()\n    X.loc[ts, f'{sensor_id}_std']       = signal.std()\n    X.loc[ts, f'{sensor_id}_var']       = signal.var() \n    X.loc[ts, f'{sensor_id}_max']       = signal.max()\n    X.loc[ts, f'{sensor_id}_min']       = signal.min()\n    X.loc[ts, f'{sensor_id}_skew']      = signal.skew()\n    X.loc[ts, f'{sensor_id}_mad']       = signal.mad()\n    X.loc[ts, f'{sensor_id}_kurtosis']  = signal.kurtosis()\n    X.loc[ts, f'{sensor_id}_quantile99']= np.quantile(signal, 0.99)\n    X.loc[ts, f'{sensor_id}_quantile95']= np.quantile(signal, 0.95)\n    X.loc[ts, f'{sensor_id}_quantile85']= np.quantile(signal, 0.85)\n    X.loc[ts, f'{sensor_id}_quantile75']= np.quantile(signal, 0.75)\n    X.loc[ts, f'{sensor_id}_quantile55']= np.quantile(signal, 0.55)\n    X.loc[ts, f'{sensor_id}_quantile45']= np.quantile(signal, 0.45) \n    X.loc[ts, f'{sensor_id}_quantile25']= np.quantile(signal, 0.25) \n    X.loc[ts, f'{sensor_id}_quantile15']= np.quantile(signal, 0.15) \n    X.loc[ts, f'{sensor_id}_quantile05']= np.quantile(signal, 0.05)\n    X.loc[ts, f'{sensor_id}_quantile01']= np.quantile(signal, 0.01)\n    X.loc[ts, f'{sensor_id}_fft_real_mean']= f_real.mean()\n    X.loc[ts, f'{sensor_id}_fft_real_std'] = f_real.std()\n    X.loc[ts, f'{sensor_id}_fft_real_max'] = f_real.max()\n    X.loc[ts, f'{sensor_id}_fft_real_min'] = f_real.min()\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-09-29T06:06:33.439065Z","iopub.execute_input":"2022-09-29T06:06:33.439541Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"0\n500\n1000\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set = list()\nj=0\nfor seg in train.segment_id:\n    signals = pd.read_csv(f'/kaggle/input/predict-volcanic-eruptions-ingv-oe/train/{seg}.csv')\n    train_row = []\n    if j%500 == 0:\n        print(j)\n    for i in range(0, 10):\n        sensor_id = f'sensor_{i+1}'\n        train_row.append(build_features(signals[sensor_id].fillna(0), seg, sensor_id))\n    train_row = pd.concat(train_row, axis=1)\n    train_set.append(train_row)\n    j+=1\n\ntrain_set = pd.concat(train_set)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = train_set.reset_index()\ntrain_set = train_set.rename(columns={'index': 'segment_id'})\ntrain_set = pd.merge(train_set, train, on='segment_id')\ntrain_set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols = list()\nfor col in train_set.columns:\n    if col == 'segment_id':\n        continue\n    if abs(train_set[col].corr(train_set['time_to_eruption'])) < 0.01:\n        drop_cols.append(col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_to_drop_cols = list()\n\nfor col1 in train_set.columns:\n    for col2 in train_set.columns:\n        if col1 == col2:\n            continue\n        if col1 == 'segment_id' or col2 == 'segment_id': \n            continue\n        if col1 == 'time_to_eruption' or col2 == 'time_to_eruption':\n            continue\n        if abs(train_set[col1].corr(train_set[col2])) > 0.98:\n            if col2 not in drop_cols and col1 not in not_to_drop_cols:\n                drop_cols.append(col2)\n                not_to_drop_cols.append(col1)\ntrain = train_set.drop(['segment_id', 'time_to_eruption'], axis=1)\ny = train_set['time_to_eruption']\nreduced_y = y.copy()\nreduced_train = train.copy()\nreduced_train = reduced_train.drop(drop_cols, axis=1)\nreduced_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val, y, y_val = train_test_split(train, y, random_state=666, test_size=0.2, shuffle=True)\nreduced_train, reduced_val, reduced_y, reduced_y_val = train_test_split(reduced_train, reduced_y, random_state=666, test_size=0.2, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost!","metadata":{}},{"cell_type":"code","source":"def test_models_cs(): \n    models_cs = dict\n    for c in np.arrange(0.05, 0.1, 0.01)\n        key = \n        models_cs[key] = xgb.XGBRFRegressor(n_estimators = 500,\n                           learning_rate = 0.05, \n                           reg_lambda = 0.1,\n                           eval_metric = mean_absolute_error, \n                           subsample = 0.9, \n                           colsample_bynode = c)\n    return models_cs\n\ndef test_models_ne(): \n    models_ne = dict\n    for n in arrange(100, 1000, 100)\n        key = \n        models_ne[key] = xgb.XGBRFRegressor(n_estimators = n,\n                           learning_rate = 0.05, \n                           reg_lambda = 0.1,\n                           eval_metric = mean_absolute_error, \n                           subsample = 0.9, \n                           colsample_bynode = 0.1)\n    return models_ne\n\ndef test_models_lr(): \n    models_lr = dict()\n    for l in arrange(0.05, 0.2, 0.05)\n        key = \n        models_lr[key] = xgb.XGBRFRegressor(n_estimators = 500,\n                           learning_rate = l, \n                           reg_lambda = 0.1,\n                           eval_metric = mean_absolute_error, \n                           subsample = 0.9, \n                           colsample_bynode = 0.1)\n    return models_lr\n    \ndef model_eval(model, X, y): \n    cross_val = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3)\n    scores = cross_val_score(model, X, y, scoring = 'accuracy', cv = cross_val)\n    return scores\n    \nmodels_cs = test_models_cs()\nresults_cs, names_cs = list(), list()\nfor name, model in models_cs.items(): \n    scores_cs = model_eval(model, reduced_train, reduced_y)\n    results_cs.append(scores_cs)\n    names_cs.append(name)\n\nmodels_ne = test_models_ne()\nresults_ne, names_ne = list(), list()\nfor name, model in models_ne.items(): \n    scores_ne = model_eval(model, reduced_train, reduced_y)\n    results_ne.append(scores_ne)\n    names_ne.append(name)\n    \nmodels_lr = test_models_ne()\nresults_lr, names_lr = list(), list()\nfor name, model in models_lr.items(): \n    scores_lr = model_eval(model, reduced_train, reduced_y)\n    results_lr.append(scores_lr)\n    names_lr.append(name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('>%s %.3f (%.3f)' % (name, mean(scores_cs), std(scores_cs)))\nprint('>%s %.3f (%.3f)' % (name, mean(scores_ne), std(scores_ne)))\nprint('>%s %.3f (%.3f)' % (name, mean(scores_lr), std(scores_lr)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (8,8))\ngs = fig.add_gridspec(2,2)\n\nfig.add_suplot(gs[0,0])\nsns.scatterplot(x = names_cs, y = results_cs)\nsns.regplot(x = names_cs, y = results_cs)\nplt.title(\"Scores by Colsample Value\")\n\nfig.add_suplot(gs[0,1])\nsns.scatterplot(x = names_ne, y = results_ne)\nsns.regplot(x = names_ne, y = results_ne)\nplt.title(\"Scores by Num Estimators\")\n\nfig.add_suplot(gs[1,0])\nsns.scatterplot(x = names_lr, y = results_lr)\nsns.regplot(x = names_lr, y = results_lr)\nplt.title(\"Scores by Learning Rate\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}